---
title: Multi-head Attention
date: 2024-04-23 00:00
modified: 2024-04-23 00:00
status: draft
---

A key layer in the [Transformer](transformer.md) architecture which represents a stack of [Scaled-Dot Product Attention](scaled-dot-product-attention.md) attention modules.

![Multi-head attention diagram](../_media/multi-head-attention.png)
