{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c756513-dd79-4a86-ab47-d803107bac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e3114-e38a-4c49-9347-f82838a8b112",
   "metadata": {},
   "source": [
    "Understanding f.pad\n",
    "\n",
    "The padding size, by which to pad some dimensions of the input, are described starting from the last dimension and moving forward.\n",
    "\n",
    "len(pad) / 2\n",
    "\n",
    "dimensions of input will be padded.\n",
    "\n",
    "For example:\n",
    "- to pad only the last dimensions of a Tensor, `pad` has the form :\n",
    "\n",
    "`(padding_left,padding_right)`\n",
    "\n",
    "- to pad the last 2 dimensions of a Tensor, `pad` has the form:\n",
    "\n",
    "`(padding_left, padding_right, padding_top, padding_bottom)`\n",
    "\n",
    "- to pad the last 3 dimensions of a Tensor, `pad` has the form:\n",
    "\n",
    "`(padding_left, padding_right, padding_top, padding_bottom, padding_front, padding_back)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d278da37-3b9d-49a8-9703-dcb6e86d1223",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2d = torch.empty(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859a1d83-03d2-458d-8f98-11c898c7b0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2d.shape, t2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9f6c89b-b54a-4b1e-bc57-40d6057c8410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 11]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(t2d, (1, 0), value=1)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "136dd205-5220-47ac-9d46-0023b8d68500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 11]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(t2d, (0, 1), value=1)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b0141ef-6b7c-4b81-8581-14eb06433858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12]),\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(t2d, (1, 1), value=1)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "422cc026-e6e4-4ffa-b497-86d66c59545d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 12]),\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(t2d, (1, 1, 1, 1), value=1)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c076b-ae95-4821-827b-9caaedca4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = F.pad(t2d, (1, 1, 1, 1), value=1)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b94471c-08d3-4c9d-a37d-27c124f55456",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1d = torch.empty(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fe6d559-2abd-44af-ac42-4b840132622b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ae2e42b-2f75-4c23-b2cf-50d4a5eca0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(t1d, (1, 0), value=1)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fde9866-90a7-43a9-8f33-92272f0b73fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), tensor([1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1d = torch.ones(5)\n",
    "t1d.shape, t1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "657805c1-acc5-428e-ab8a-393e81ce3a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6]), tensor([0., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(t1d, (1, 0), value=0)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b04687e8-481a-4a01-8d42-802bacd85a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 10]),\n",
       " tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3d = torch.ones(1, 5, 10)\n",
    "t3d.shape, t3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd318ae8-83f7-47b0-9ab3-c4570716baef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 5, 11]),\n",
       " tensor([[[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(t3d, (1, 0), value=0)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b1e5eee-4c2e-45f6-bc76-4f1575112a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7, 10]),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(t3d, (0, 0, 1, 1), value=0)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aefd5a9b-8213-49bf-a3b7-870c200b8de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 7, 10]),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(t3d, (0, 0, 1, 1, 1, 1), value=0)\n",
    "p.shape, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52868054-d2b1-4c5d-a4ea-d8ca59c32f59",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Padding mode:\n",
    "See torch.nn.CircularPad2d, torch.nn.ConstantPad2d, torch.nn.ReflectionPad2d, and torch.nn.ReplicationPad2d for concrete examples on how each of the padding modes works. Constant padding is implemented for arbitrary dimensions. Circular, replicate and reflection padding are implemented for padding the last 3 dimensions of a 4D or 5D input tensor, the last 2 dimensions of a 3D or 4D input tensor, or the last dimension of a 2D or 3D input tensor.\n",
    "\n",
    "---\n",
    "\n",
    "mode – 'constant', 'reflect', 'replicate' or 'circular'. Default: 'constant'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529bc50-43c6-4112-9e70-faddc76c2336",
   "metadata": {},
   "source": [
    "value – fill value for 'constant' padding. Default: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "997e3387-a1e3-49d7-a226-fb9782d97cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 2, 3, 0, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(torch.tensor([[1, 2, 3]]), (2, 2),  mode=\"constant\", value=0)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa75511c-f820-4fd6-a831-ea5bde2cfb17",
   "metadata": {},
   "source": [
    "value – fill value for 'reflect' padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df11dda7-4c80-4b03-9f12-e1af1b7d52ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2, 1, 2, 3, 2, 1]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(torch.tensor([[1, 2, 3]]), (2, 2),  mode=\"reflect\")\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85071cfc-7b1d-4283-aaa7-70f8ea6bebaf",
   "metadata": {},
   "source": [
    "replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e30d47d4-ceef-43b3-909c-19bfab47d8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 2, 3, 3, 3]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(torch.tensor([[1, 2, 3]]), (2, 2),  mode=\"replicate\")\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2317dac-6740-4194-b483-b299b0da9615",
   "metadata": {},
   "source": [
    "circular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba885943-1dc4-4b8c-a64e-59ab29690e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 1, 2, 3, 1, 2]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = F.pad(torch.tensor([[1, 2, 3]]), (2, 2),  mode=\"circular\")\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437665bf-dd57-472d-9339-76acf111ff58",
   "metadata": {},
   "source": [
    "## Use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6be38a72-3ecd-4d4c-9e3d-72c362ba1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {\n",
    "    \"Hello\": 1,\n",
    "    \"world\": 2,\n",
    "    \"What\": 3,\n",
    "    \"is\": 4,\n",
    "    \"happening\": 5,\n",
    "    \"here\": 6,\n",
    "    \"everyone\": 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c5ef772-4809-499c-af04-da79dee3270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Hello world\",\n",
    "    \"What is happening here everyone\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24e6d0-0341-43fe-8465-5c19aac0598b",
   "metadata": {},
   "source": [
    "Since Tensors have to have consistent dimensions, the batch has to be stretched to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b894ba9e-d2b9-4edd-8e1e-6db0652cdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokens = torch.Tensor([\n",
    "    [1, 2, 0, 0, 0],\n",
    "    [3, 4, 5, 6, 7]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59106353-b6ac-49a1-afc4-b39b3b50c8db",
   "metadata": {},
   "source": [
    "We can create a pad mask to allow us to perform operations, only on the places that have genuine tokens.\n",
    "\n",
    "To do that, we might create a bool where True represents the areas to mask. In our example, it might look like:\n",
    "\n",
    "```python\n",
    "[\n",
    "    [False, False, True, True, True],\n",
    "    [False, False, False, False, False]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11012ed6-c0bc-49bf-aeac-919a28af6612",
   "metadata": {},
   "source": [
    "We might expect to have a 1d tensor that represents the length of each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0212eda1-6f09-426d-89b4-29fcf66add7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = torch.Tensor([2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afcd9570-9863-4e89-9f3b-401266f860ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b3b1af1-6f64-4477-b467-86eb7d796bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_range = torch.arange(0, lens.max())\n",
    "seq_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "314ab2a8-f154-46b4-8981-bc6bc5cd6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4.],\n",
       "        [0., 1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_lengths = seq_range.unsqueeze(0).expand(lens.size(0), int(lens.max()))\n",
    "expanded_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cbd8d4c6-c2ff-4b41-b694-29121e0cb684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True,  True,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_mask = expanded_lengths >= lens.unsqueeze(-1)\n",
    "sentence_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59886286-cf8a-4a36-9abb-4e205a40b916",
   "metadata": {},
   "source": [
    "We can use that to add a EOS token. For example, here I'm adding the EOS token represented by integer 100 to the end of each sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9f9a779-ace6-4c32-b740-fc665b48a541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   2., 100., 100., 100., 100.],\n",
       "        [  3.,   4.,   5.,   6.,   7., 100.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos = 100\n",
    "eos_padded = F.pad(sentence_tokens, (0, 1), value=0) + eos * F.pad(sentence_mask, (0, 1), value=1)\n",
    "eos_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f465b-715a-4795-a5b2-83cd4e37847c",
   "metadata": {},
   "source": [
    "Or I can prepend a \"beginning of sequence\" (BOS) token as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed4c1a50-2921-413b-9dcb-ab4fc222d168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[101.,   1.,   2., 100., 100., 100.],\n",
       "        [101.,   3.,   4.,   5.,   6.,   7.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(eos_padded[:, :-1], (1, 0), value=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988cea71-ddec-4007-abe9-ecbc5a8b310d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
