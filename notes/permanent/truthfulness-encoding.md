---
title: Truthfulness Encoding
date: 2024-10-07 00:00
modified: 2024-10-07 00:00
status: draft
---

**Truthfulness Encoding** refers to the phenomenon where the internal representations of large language models (LLMs) contain information about the truthfulness of their generated outputs.

In the paper [LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations](../reference/papers/llms-know-more-than-they-show-on-the-intrinsic-representation-of-llm-hallucinations.md), they observed that the truthfulness encoding is distributed across multiple mechanisms, specific to the skill being assessed, rather than a single universal mechanism.
