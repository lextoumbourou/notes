---
title: Survivorship Bias
date: 2021-06-01 00:00
tags:
  - ErrorsOfThinking
cover: /_media/world-war-2-aircraft-survivorship-bias-abraham-wald-17.jpeg
---

Survivorship Bias is a common error of thinking where we arrive at false conclusions by only examining success cases.

For example, on one of my former teams, some of us had been keeping tabs on how well Microservices had worked at NetFlix and we didn't want to miss out. We made a collective decision to start a new project following a strict Microservice architecture. 

However, we failed to take into account the stories of where Microservices hadn't worked out, discovering for ourselves how much unnecessary complexity they introduce for a small team. This was so common in tech that Thoughtworks named it [Microservice Envy](https://www.thoughtworks.com/radar/techniques/microservice-envy) in their 2015 Radar.

Every page about Survivorship Bias has to include the story of [Abraham Wald](https://en.wikipedia.org/wiki/Survivorship_bias#In_the_military). During WW2, he and his team were instructed to recommend which parts of fighter planes they should reinforce based on an assessment of the damage they took during battle. At odds with recomendations from the US military, he recommended that they reinforce the parts of the plane that took no damage. The planes that had been hit in those areas never made it back.

Another error of thinking like [[Confirmation Bias]].

[@ahrensHowTakeSmart2017] *(pg. 136)*