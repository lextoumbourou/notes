{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch import nn\nimport numpy as np\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:27.930497Z","iopub.execute_input":"2022-02-08T22:07:27.930827Z","iopub.status.idle":"2022-02-08T22:07:29.411858Z","shell.execute_reply.started":"2022-02-08T22:07:27.930743Z","shell.execute_reply":"2022-02-08T22:07:29.411003Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"This notebook uses code from [this](https://github.com/pbloem/former/blob/master/former/modules.py) in an effort to understand the details of the paper: [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)","metadata":{}},{"cell_type":"code","source":"# We'll come back to this.\n\nclass SelfAttention(nn.Module):\n    \"\"\"\n    Canonical implementation of multi-head self attention.\n    \"\"\"\n\n    def __init__(self, emb, heads=8, mask=False):\n        \"\"\"\n        :param emb:\n        :param heads:\n        :param mask:\n        \"\"\"\n\n        super().__init__()\n\n        assert emb % heads == 0, f'Embedding dimension ({emb}) should be divisible by nr. of heads ({heads})'\n\n        self.emb = emb\n        self.heads = heads\n        self.mask = mask\n\n        s = emb // heads\n        # - We will break the embedding into `heads` chunks and feed each to a different attention head\n\n        self.tokeys    = nn.Linear(emb, emb, bias=False)\n        self.toqueries = nn.Linear(emb, emb, bias=False)\n        self.tovalues  = nn.Linear(emb, emb, bias=False)\n\n        self.unifyheads = nn.Linear(emb, emb)\n\n    def forward(self, x):\n\n        b, t, e = x.size()\n        h = self.heads\n        assert e == self.emb, f'Input embedding dim ({e}) should match layer embedding dim ({self.emb})'\n\n        s = e // h\n\n        keys    = self.tokeys(x)\n        queries = self.toqueries(x)\n        values  = self.tovalues(x)\n\n        keys    = keys.view(b, t, h, s)\n        queries = queries.view(b, t, h, s)\n        values  = values.view(b, t, h, s)\n\n        # -- We first compute the k/q/v's on the whole embedding vectors, and then split into the different heads.\n        #    See the following video for an explanation: https://youtu.be/KmAISyVvE1Y\n\n        # Compute scaled dot-product self-attention\n\n        # - fold heads into the batch dimension\n        keys = keys.transpose(1, 2).contiguous().view(b * h, t, s)\n        queries = queries.transpose(1, 2).contiguous().view(b * h, t, s)\n        values = values.transpose(1, 2).contiguous().view(b * h, t, s)\n\n        queries = queries / (e ** (1/4))\n        keys    = keys / (e ** (1/4))\n        # - Instead of dividing the dot products by sqrt(e), we scale the keys and values.\n        #   This should be more memory efficient\n\n        # - get dot product of queries and keys, and scale\n        dot = torch.bmm(queries, keys.transpose(1, 2))\n\n        assert dot.size() == (b*h, t, t)\n\n        if self.mask: # mask out the upper half of the dot matrix, excluding the diagonal\n            mask_(dot, maskval=float('-inf'), mask_diagonal=False)\n\n        dot = F.softmax(dot, dim=2)\n        # - dot now has row-wise self-attention probabilities\n\n        # apply the self attention to the values\n        out = torch.bmm(dot, values).view(b, h, t, s)\n\n        # swap h, t back, unify heads\n        out = out.transpose(1, 2).contiguous().view(b, t, s * h)\n\n        return self.unifyheads(out)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-08T22:07:29.413106Z","iopub.execute_input":"2022-02-08T22:07:29.413585Z","iopub.status.idle":"2022-02-08T22:07:29.428001Z","shell.execute_reply.started":"2022-02-08T22:07:29.413558Z","shell.execute_reply":"2022-02-08T22:07:29.426834Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(\n        self,\n        emb_size: int,\n        heads: int,\\\n        seq_length,\n        ff_hidden_mult=4,\n        dropout=0.0,\n        pos_embedding=None\n):\n        super().__init__()\n\n        self.attention = SelfAttention(emb_size)\n\n        self.norm1 = nn.LayerNorm(emb_size)\n        self.norm2 = nn.LayerNorm(emb_size)\n\n        self.feed_forward = nn.Sequential(\n            nn.Linear(emb_size, ff_hidden_mult * emb_size),\n            nn.ReLU(),\n            nn.Linear(ff_hidden_mult * emb_size, emb_size)\n        )\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        attention_out = self.attention(x)\n        x = self.norm1(attention_out + x)\n        x = self.dropout(x)\n        \n        feed_forward = self.feed_forward(x)\n        x = self.norm2(feed_forward + x)\n        x = self.dropout(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:53.794327Z","iopub.execute_input":"2022-02-08T22:07:53.794670Z","iopub.status.idle":"2022-02-08T22:07:53.803603Z","shell.execute_reply.started":"2022-02-08T22:07:53.794644Z","shell.execute_reply":"2022-02-08T22:07:53.802427Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(\n        self,\n        emb_size: int,\n        heads: int,\n        num_tokens: int,\n        seq_length: int,\n        max_pool: bool = True,\n        dropout: int=0\n    ):\n        super().__init__()\n        \n        self.num_tokens, self.max_pool = num_tokens, max_pool\n        \n        self.token_embedding = nn.Embedding(embedding_dim=emb_size, num_embeddings=num_tokens)\n        self.pos_embedding = nn.Embedding(embedding_dim=emb_size, num_embeddings=seq_length)\n        \n        tblocks = []\n        for i in range(heads):\n            tblocks.append(TransformerBlock(emb_size=emb_size, heads=heads, seq_length=seq_length))\n            \n        self.tblocks = nn.Sequential(*tblocks)\n        \n        self.toprobs = nn.Linear(emb_size, 2)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        \"\"\"\n        x: Batch by sequence length integer tensor of token indices.\n        \n        Return: predicted log-probs vectors for each token based on preceding tokens.\n        \"\"\"\n        tokens = self.token_embedding(x)\n        batch_size, seq_length, emb_size = tokens.size()\n        \n        positions = self.pos_embedding(torch.arange(t, device=d()))[None, :, :].expand(b, t, e)\n        x = tokens + positions\n        x = self.dropout(x)\n        \n        x = self.tblocks(x)\n\n        x = x.max(dim=1)[0] if self.max_pool else x.mean(dim=1) # pool over the time dimension\n\n        x = self.toprobs(x)\n\n        return F.log_softmax(x, dim=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:54.265750Z","iopub.execute_input":"2022-02-08T22:07:54.266077Z","iopub.status.idle":"2022-02-08T22:07:54.276094Z","shell.execute_reply.started":"2022-02-08T22:07:54.266053Z","shell.execute_reply":"2022-02-08T22:07:54.275214Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Next steps:\n\n1. Create a basic input and output example.\n2. Add a batch dimension.\n3. Feed it into the model and view the returned sizes.\n4. Use it to breakdown the inside of Transformer./","metadata":{}},{"cell_type":"code","source":"vocab = {'this': 0, 'is': 1, 'awesome': 2, 'i': 3, 'hated': 4, 'it': 5}\n\ntrain_data = [\n    {'text': 'this is awesome', 'label': True},\n    {'text': 'i hated it', 'label': False}\n]\n\ndef tokenise(txt: str):\n    return txt.split()\n\ndef numericise(tokens):\n    return [vocab[t] for t in tokens]\n\ntokens = []\nlabels = []\nfor row in train_data:\n    tokens.append(numericise(tokenise(row['text'])))\n    labels.append(row['label'])\ntokens = np.array(tokens)\nlabels = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:54.532767Z","iopub.execute_input":"2022-02-08T22:07:54.533008Z","iopub.status.idle":"2022-02-08T22:07:54.540139Z","shell.execute_reply.started":"2022-02-08T22:07:54.532983Z","shell.execute_reply":"2022-02-08T22:07:54.539406Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(tokens); print(tokens.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:54.662737Z","iopub.execute_input":"2022-02-08T22:07:54.662955Z","iopub.status.idle":"2022-02-08T22:07:54.668890Z","shell.execute_reply.started":"2022-02-08T22:07:54.662932Z","shell.execute_reply":"2022-02-08T22:07:54.667738Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"labels, labels.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:54.797537Z","iopub.execute_input":"2022-02-08T22:07:54.797796Z","iopub.status.idle":"2022-02-08T22:07:54.805875Z","shell.execute_reply.started":"2022-02-08T22:07:54.797772Z","shell.execute_reply":"2022-02-08T22:07:54.804466Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"tokens = np.array(tokens)\nlabels = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:54.937685Z","iopub.execute_input":"2022-02-08T22:07:54.937945Z","iopub.status.idle":"2022-02-08T22:07:54.943410Z","shell.execute_reply.started":"2022-02-08T22:07:54.937916Z","shell.execute_reply":"2022-02-08T22:07:54.942165Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"tokens.shape, labels.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:55.076409Z","iopub.execute_input":"2022-02-08T22:07:55.076653Z","iopub.status.idle":"2022-02-08T22:07:55.082704Z","shell.execute_reply.started":"2022-02-08T22:07:55.076627Z","shell.execute_reply":"2022-02-08T22:07:55.081731Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"EMB_SIZE = 512","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:55.184545Z","iopub.execute_input":"2022-02-08T22:07:55.184811Z","iopub.status.idle":"2022-02-08T22:07:55.188772Z","shell.execute_reply.started":"2022-02-08T22:07:55.184782Z","shell.execute_reply":"2022-02-08T22:07:55.188085Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = Transformer(emb_size=EMB_SIZE, heads=6, num_tokens=3, seq_length=3)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:55.343485Z","iopub.execute_input":"2022-02-08T22:07:55.344028Z","iopub.status.idle":"2022-02-08T22:07:55.467960Z","shell.execute_reply.started":"2022-02-08T22:07:55.343987Z","shell.execute_reply":"2022-02-08T22:07:55.467003Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:55.478308Z","iopub.execute_input":"2022-02-08T22:07:55.478561Z","iopub.status.idle":"2022-02-08T22:07:55.484792Z","shell.execute_reply.started":"2022-02-08T22:07:55.478536Z","shell.execute_reply":"2022-02-08T22:07:55.484123Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"tokens","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:55.614575Z","iopub.execute_input":"2022-02-08T22:07:55.614840Z","iopub.status.idle":"2022-02-08T22:07:55.620381Z","shell.execute_reply.started":"2022-02-08T22:07:55.614814Z","shell.execute_reply":"2022-02-08T22:07:55.619649Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"tokens_arr = torch.from_numpy(tokens)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:55.756496Z","iopub.execute_input":"2022-02-08T22:07:55.756789Z","iopub.status.idle":"2022-02-08T22:07:55.760968Z","shell.execute_reply.started":"2022-02-08T22:07:55.756762Z","shell.execute_reply":"2022-02-08T22:07:55.760332Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Before breaking down the Transformer, let's look at the inputs to the model.\n\nWe'll firstly create a token embedding. Which is a structure that assigns a vector of 512 for each token in our vocab.\n\n#### Token embedding\n\nIn Attention Is All You Need, they set all outputs sizes to 512, including embeddings. So we'll do that.\n\n![image.png](attachment:a8d7ee79-63e8-44ed-91bc-29558c4f6572.png)","metadata":{},"attachments":{"a8d7ee79-63e8-44ed-91bc-29558c4f6572.png":{"image/png":"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"}}},{"cell_type":"code","source":"embedding_size = 512","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:56.029641Z","iopub.execute_input":"2022-02-08T22:07:56.029874Z","iopub.status.idle":"2022-02-08T22:07:56.032372Z","shell.execute_reply.started":"2022-02-08T22:07:56.029850Z","shell.execute_reply":"2022-02-08T22:07:56.031923Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"token_embedding = nn.Embedding(embedding_dim=embedding_size, num_embeddings=len(vocab.keys()))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:56.164597Z","iopub.execute_input":"2022-02-08T22:07:56.164946Z","iopub.status.idle":"2022-02-08T22:07:56.168271Z","shell.execute_reply.started":"2022-02-08T22:07:56.164922Z","shell.execute_reply":"2022-02-08T22:07:56.167826Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"token_embedding","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:56.282558Z","iopub.execute_input":"2022-02-08T22:07:56.282911Z","iopub.status.idle":"2022-02-08T22:07:56.287108Z","shell.execute_reply.started":"2022-02-08T22:07:56.282886Z","shell.execute_reply":"2022-02-08T22:07:56.286414Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"token_embedding(torch.from_numpy(np.array([0, 1])))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:56.452441Z","iopub.execute_input":"2022-02-08T22:07:56.452785Z","iopub.status.idle":"2022-02-08T22:07:56.460461Z","shell.execute_reply.started":"2022-02-08T22:07:56.452755Z","shell.execute_reply":"2022-02-08T22:07:56.459321Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"### Position embedding","metadata":{}},{"cell_type":"code","source":"seq_length = 3  # Each training example has 3 words in the sequence.\n\npos_embedding = nn.Embedding(embedding_dim=embedding_size, num_embeddings=seq_length)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:56.712668Z","iopub.execute_input":"2022-02-08T22:07:56.712950Z","iopub.status.idle":"2022-02-08T22:07:56.719387Z","shell.execute_reply.started":"2022-02-08T22:07:56.712923Z","shell.execute_reply":"2022-02-08T22:07:56.718224Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"Now, in the forward pass, we take the embedding values for our tokens:","metadata":{}},{"cell_type":"code","source":"tokens_arr.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:57.249573Z","iopub.execute_input":"2022-02-08T22:07:57.249916Z","iopub.status.idle":"2022-02-08T22:07:57.255712Z","shell.execute_reply.started":"2022-02-08T22:07:57.249891Z","shell.execute_reply":"2022-02-08T22:07:57.254404Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"tokens = token_embedding(tokens_arr)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:57.406904Z","iopub.execute_input":"2022-02-08T22:07:57.408155Z","iopub.status.idle":"2022-02-08T22:07:57.413027Z","shell.execute_reply.started":"2022-02-08T22:07:57.408109Z","shell.execute_reply":"2022-02-08T22:07:57.411733Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"tokens.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:57.570831Z","iopub.execute_input":"2022-02-08T22:07:57.571099Z","iopub.status.idle":"2022-02-08T22:07:57.576576Z","shell.execute_reply.started":"2022-02-08T22:07:57.571072Z","shell.execute_reply":"2022-02-08T22:07:57.575471Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"tokens.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:57.922533Z","iopub.execute_input":"2022-02-08T22:07:57.922877Z","iopub.status.idle":"2022-02-08T22:07:57.927698Z","shell.execute_reply.started":"2022-02-08T22:07:57.922846Z","shell.execute_reply":"2022-02-08T22:07:57.926886Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"batch_size, seq_length, emb_length = tokens.size()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:58.087118Z","iopub.execute_input":"2022-02-08T22:07:58.087934Z","iopub.status.idle":"2022-02-08T22:07:58.092443Z","shell.execute_reply.started":"2022-02-08T22:07:58.087902Z","shell.execute_reply":"2022-02-08T22:07:58.091135Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"What are we doing here?\n\nIf I have a sequence length of 3, then the position array is just: [0, 1, 2]","metadata":{}},{"cell_type":"code","source":"torch.arange(seq_length)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:58.648518Z","iopub.execute_input":"2022-02-08T22:07:58.648752Z","iopub.status.idle":"2022-02-08T22:07:58.654155Z","shell.execute_reply.started":"2022-02-08T22:07:58.648729Z","shell.execute_reply":"2022-02-08T22:07:58.653743Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"position_sequence = torch.arange(seq_length)\nposition_sequence.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:58.856537Z","iopub.execute_input":"2022-02-08T22:07:58.856966Z","iopub.status.idle":"2022-02-08T22:07:58.862984Z","shell.execute_reply.started":"2022-02-08T22:07:58.856938Z","shell.execute_reply":"2022-02-08T22:07:58.861583Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"positions = pos_embedding(position_sequence)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:59.043483Z","iopub.execute_input":"2022-02-08T22:07:59.044163Z","iopub.status.idle":"2022-02-08T22:07:59.047750Z","shell.execute_reply.started":"2022-02-08T22:07:59.044136Z","shell.execute_reply":"2022-02-08T22:07:59.046987Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"We add the batch dimension, them duplicate for each sequence.","metadata":{}},{"cell_type":"code","source":"positions = positions[None,:,:]\npositions.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:07:59.630642Z","iopub.execute_input":"2022-02-08T22:07:59.630989Z","iopub.status.idle":"2022-02-08T22:07:59.635611Z","shell.execute_reply.started":"2022-02-08T22:07:59.630953Z","shell.execute_reply":"2022-02-08T22:07:59.635123Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"Now duplicate that so there's one for each of our sequences.","metadata":{}},{"cell_type":"code","source":"positions = positions.expand(batch_size, seq_length, emb_length)\npositions.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:08:00.109243Z","iopub.execute_input":"2022-02-08T22:08:00.110032Z","iopub.status.idle":"2022-02-08T22:08:00.115843Z","shell.execute_reply.started":"2022-02-08T22:08:00.110003Z","shell.execute_reply":"2022-02-08T22:08:00.114852Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"Now we add these tokens.","metadata":{}},{"cell_type":"code","source":"x = tokens + positions","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:08:00.672577Z","iopub.execute_input":"2022-02-08T22:08:00.672808Z","iopub.status.idle":"2022-02-08T22:08:00.677363Z","shell.execute_reply.started":"2022-02-08T22:08:00.672784Z","shell.execute_reply":"2022-02-08T22:08:00.676226Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"This input can be fed into the neural network.\n\n","metadata":{}},{"cell_type":"markdown","source":"### Encoder","metadata":{}},{"cell_type":"markdown","source":"The encoder is composed of a stack of N = 6 identical layers, which we'll call `TransformerBlock`","metadata":{}},{"cell_type":"code","source":"tblocks = [TransformerBlock(emb_size=embedding_size, heads=8, seq_length=3)] * 6","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:09:08.548695Z","iopub.execute_input":"2022-02-08T22:09:08.549173Z","iopub.status.idle":"2022-02-08T22:09:08.572184Z","shell.execute_reply.started":"2022-02-08T22:09:08.549136Z","shell.execute_reply":"2022-02-08T22:09:08.570939Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"model = nn.Sequential(*tblocks)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:09:09.357676Z","iopub.execute_input":"2022-02-08T22:09:09.358117Z","iopub.status.idle":"2022-02-08T22:09:09.361791Z","shell.execute_reply.started":"2022-02-08T22:09:09.358081Z","shell.execute_reply":"2022-02-08T22:09:09.361295Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"model[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:09:14.110714Z","iopub.execute_input":"2022-02-08T22:09:14.111128Z","iopub.status.idle":"2022-02-08T22:09:14.119231Z","shell.execute_reply.started":"2022-02-08T22:09:14.111102Z","shell.execute_reply":"2022-02-08T22:09:14.118001Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"model(x).shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:09:17.497956Z","iopub.execute_input":"2022-02-08T22:09:17.498215Z","iopub.status.idle":"2022-02-08T22:09:17.524080Z","shell.execute_reply.started":"2022-02-08T22:09:17.498191Z","shell.execute_reply":"2022-02-08T22:09:17.522786Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"Each layer has two sub-layers. The first is a *multi-head self-attention mechanism*, and the second is a simple, positionwise fully connected feed-forward network.\n\nLet's explore the multi-head self-attention mechanism first.\n\n#### Multi-head self-attention\n\nThe paper says:\n\n*An attention function can be described as mapping a query and a set of key-value pairs to an output,\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\nof the values, where the weight assigned to each value is computed by a compatibility function of the\nquery with the corresponding key.*","metadata":{}},{"cell_type":"markdown","source":"The code creates 4 Linear layers that have embedding_size inputs and outputs.","metadata":{}},{"cell_type":"code","source":"tokeys = nn.Linear(embedding_size, embedding_size, bias=False)\ntoqueries = nn.Linear(embedding_size, embedding_size, bias=False)\ntovalues = nn.Linear(embedding_size, embedding_size, bias=False)\n\nunifyheads = nn.Linear(embedding_size, embedding_size)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:17:47.536069Z","iopub.execute_input":"2022-02-08T22:17:47.536302Z","iopub.status.idle":"2022-02-08T22:17:47.546827Z","shell.execute_reply.started":"2022-02-08T22:17:47.536278Z","shell.execute_reply":"2022-02-08T22:17:47.545982Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"We feed out token and position concatted embedding vector into the layers.","metadata":{}},{"cell_type":"code","source":"keys = tokeys(x)\nqueries = toqueries(x)\nvalues = tovalues(x)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:19:35.460068Z","iopub.execute_input":"2022-02-08T22:19:35.460793Z","iopub.status.idle":"2022-02-08T22:19:35.466408Z","shell.execute_reply.started":"2022-02-08T22:19:35.460753Z","shell.execute_reply":"2022-02-08T22:19:35.465653Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"keys.shape, queries.shape, values.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:19:46.763093Z","iopub.execute_input":"2022-02-08T22:19:46.763941Z","iopub.status.idle":"2022-02-08T22:19:46.771986Z","shell.execute_reply.started":"2022-02-08T22:19:46.763893Z","shell.execute_reply":"2022-02-08T22:19:46.770800Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"Now we split those into 6 head values.","metadata":{}},{"cell_type":"code","source":"num_heads = 8\nhead_size = embedding_size // num_heads\nhead_size","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:22:21.783179Z","iopub.execute_input":"2022-02-08T22:22:21.783785Z","iopub.status.idle":"2022-02-08T22:22:21.788661Z","shell.execute_reply.started":"2022-02-08T22:22:21.783756Z","shell.execute_reply":"2022-02-08T22:22:21.788138Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"batch_size, seq_length, emb_length = x.size()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:22:22.592687Z","iopub.execute_input":"2022-02-08T22:22:22.593371Z","iopub.status.idle":"2022-02-08T22:22:22.597497Z","shell.execute_reply.started":"2022-02-08T22:22:22.593342Z","shell.execute_reply":"2022-02-08T22:22:22.596949Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"keys = keys.view(batch_size, seq_length, num_heads, head_size)\nqueries = queries.view(batch_size, seq_length, num_heads, head_size)\nvalues  = values.view(batch_size, seq_length, num_heads, head_size)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:22:22.786746Z","iopub.execute_input":"2022-02-08T22:22:22.787197Z","iopub.status.idle":"2022-02-08T22:22:22.790719Z","shell.execute_reply.started":"2022-02-08T22:22:22.787169Z","shell.execute_reply":"2022-02-08T22:22:22.790192Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"The next step is to \"fold the heads into the batch dimension\". Why we do this i'm not sure, but we're converting the size from:\n\nbatch, seq_len, num_heads, head_size\n\ninto\n\nbatch_size * num_heads, seq_length, head_size","metadata":{}},{"cell_type":"code","source":"keys.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:22:28.941055Z","iopub.execute_input":"2022-02-08T22:22:28.941299Z","iopub.status.idle":"2022-02-08T22:22:28.947109Z","shell.execute_reply.started":"2022-02-08T22:22:28.941274Z","shell.execute_reply":"2022-02-08T22:22:28.945950Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"keys_transposed = keys.transpose(1, 2)\nkeys_transposed.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:36:15.705785Z","iopub.execute_input":"2022-02-08T22:36:15.706035Z","iopub.status.idle":"2022-02-08T22:36:15.712587Z","shell.execute_reply.started":"2022-02-08T22:36:15.706011Z","shell.execute_reply":"2022-02-08T22:36:15.711803Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"\nWhen you call contiguous() , it actually makes a copy of the tensor such that the order of its elements in memory is the same as if it had been created from scratch with the same data.\nhttps://stackoverflow.com/questions/48915810/pytorch-what-does-contiguous-do","metadata":{}},{"cell_type":"code","source":"# This converts a view into a tensor that acts as if being created from scratch.\nkeys_contiguous = keys.transpose(1, 2).contiguous()\nkeys_contiguous.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:36:59.083241Z","iopub.execute_input":"2022-02-08T22:36:59.083608Z","iopub.status.idle":"2022-02-08T22:36:59.089925Z","shell.execute_reply.started":"2022-02-08T22:36:59.083585Z","shell.execute_reply":"2022-02-08T22:36:59.088734Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"keys_view = keys_contiguous.view(batch_size * num_heads, seq_length, head_size)\nkeys_view.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:37:12.364560Z","iopub.execute_input":"2022-02-08T22:37:12.365453Z","iopub.status.idle":"2022-02-08T22:37:12.370764Z","shell.execute_reply.started":"2022-02-08T22:37:12.365422Z","shell.execute_reply":"2022-02-08T22:37:12.370316Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"We do that for keys, queries and values.","metadata":{}},{"cell_type":"code","source":"keys = keys.transpose(1, 2).contiguous().view(batch_size * num_heads, seq_length, head_size)\nqueries = queries.transpose(1, 2).contiguous().view(batch_size * num_heads, seq_length, head_size)\nvalues = values.transpose(1, 2).contiguous().view(batch_size * num_heads, seq_length, head_size)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:37:42.343667Z","iopub.execute_input":"2022-02-08T22:37:42.344057Z","iopub.status.idle":"2022-02-08T22:37:42.349378Z","shell.execute_reply.started":"2022-02-08T22:37:42.344015Z","shell.execute_reply":"2022-02-08T22:37:42.347791Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"This code I don't get. Something about scaling by embedding size","metadata":{}},{"cell_type":"code","source":"queries = queries / (embedding_size ** (1/4))\nkeys = keys / (embedding_size ** (1/4))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:39:14.350363Z","iopub.execute_input":"2022-02-08T22:39:14.350621Z","iopub.status.idle":"2022-02-08T22:39:14.354996Z","shell.execute_reply.started":"2022-02-08T22:39:14.350595Z","shell.execute_reply":"2022-02-08T22:39:14.354336Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"Now we take a dot product of queries and keys, then scale. Need to understand the `bmm` function.","metadata":{}},{"cell_type":"code","source":"dot = torch.bmm(queries, keys.transpose(1, 2))","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:40:03.599822Z","iopub.execute_input":"2022-02-08T22:40:03.600151Z","iopub.status.idle":"2022-02-08T22:40:03.605590Z","shell.execute_reply.started":"2022-02-08T22:40:03.600121Z","shell.execute_reply":"2022-02-08T22:40:03.604626Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"We now convert dot into row-wise self-attention probabilities.","metadata":{}},{"cell_type":"code","source":"dot = F.softmax(dot, dim=2)\ndot.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:43:17.942112Z","iopub.execute_input":"2022-02-08T22:43:17.942391Z","iopub.status.idle":"2022-02-08T22:43:17.948688Z","shell.execute_reply.started":"2022-02-08T22:43:17.942364Z","shell.execute_reply":"2022-02-08T22:43:17.947805Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"We now apply self-attention to the values.","metadata":{}},{"cell_type":"code","source":"out = torch.bmm(dot, values).view(batch_size, num_heads, seq_length, head_size)\nout.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:44:44.117844Z","iopub.execute_input":"2022-02-08T22:44:44.118196Z","iopub.status.idle":"2022-02-08T22:44:44.122756Z","shell.execute_reply.started":"2022-02-08T22:44:44.118173Z","shell.execute_reply":"2022-02-08T22:44:44.122308Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":"Now we swap num_heads and seq_length before unifying heads.","metadata":{}},{"cell_type":"code","source":"out = out.transpose(1, 2)\nout.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:45:57.192193Z","iopub.execute_input":"2022-02-08T22:45:57.192454Z","iopub.status.idle":"2022-02-08T22:45:57.198757Z","shell.execute_reply.started":"2022-02-08T22:45:57.192428Z","shell.execute_reply":"2022-02-08T22:45:57.197752Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"out = out.contiguous().view(batch_size, seq_length, num_heads * head_size)\nout.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:46:25.383362Z","iopub.execute_input":"2022-02-08T22:46:25.383611Z","iopub.status.idle":"2022-02-08T22:46:25.390651Z","shell.execute_reply.started":"2022-02-08T22:46:25.383585Z","shell.execute_reply":"2022-02-08T22:46:25.389934Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"Finally we unify heads.","metadata":{}},{"cell_type":"code","source":"out = unifyheads(out)\nout.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-08T22:46:44.136910Z","iopub.execute_input":"2022-02-08T22:46:44.137393Z","iopub.status.idle":"2022-02-08T22:46:44.143735Z","shell.execute_reply.started":"2022-02-08T22:46:44.137363Z","shell.execute_reply":"2022-02-08T22:46:44.143161Z"},"trusted":true},"execution_count":112,"outputs":[]}]}