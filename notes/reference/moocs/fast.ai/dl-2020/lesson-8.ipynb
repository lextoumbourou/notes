{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9ea983",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-09T11:32:23.917246Z",
     "iopub.status.busy": "2021-08-09T11:32:23.916545Z",
     "iopub.status.idle": "2021-08-09T11:34:41.811011Z",
     "shell.execute_reply": "2021-08-09T11:34:41.810382Z"
    },
    "papermill": {
     "duration": 137.94401,
     "end_time": "2021-08-09T11:34:41.811176",
     "exception": false,
     "start_time": "2021-08-09T11:32:23.867166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/fastai/fastai.git &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7005c3",
   "metadata": {
    "papermill": {
     "duration": 0.034773,
     "end_time": "2021-08-09T11:34:41.880301",
     "exception": false,
     "start_time": "2021-08-09T11:34:41.845528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:00:00 - Intro and NLP Review\n",
    "\n",
    "* In Lesson 1, we create a sentiment classifier, but haven't looked at what's going on behind the scene.\n",
    "\n",
    "## 00:01:31 - Language models in NLP\n",
    "\n",
    "* The pretrained model we used for the IMDB sentiment analysis, was a pretrained language model.\n",
    "* One example of a language model: trying to predict next word of text.\n",
    "  * To be able to this, a language needs to have a good understanding of language.\n",
    "* You can download pretrained language models through various Model Zoos.\n",
    "  \n",
    "## 00:04:36 - Review of lesson 1.\n",
    "\n",
    "* We downloaded a pretrained model and fine tuned it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543f7c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T11:34:41.952913Z",
     "iopub.status.busy": "2021-08-09T11:34:41.952166Z",
     "iopub.status.idle": "2021-08-09T12:00:57.810327Z",
     "shell.execute_reply": "2021-08-09T12:00:57.809793Z"
    },
    "papermill": {
     "duration": 1575.89685,
     "end_time": "2021-08-09T12:00:57.810513",
     "exception": false,
     "start_time": "2021-08-09T11:34:41.913663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [144441344/144440600 00:03<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [105070592/105067061 00:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.449429</td>\n",
       "      <td>0.379644</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>02:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.297342</td>\n",
       "      <td>0.359466</td>\n",
       "      <td>0.860680</td>\n",
       "      <td>04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>0.222691</td>\n",
       "      <td>0.910480</td>\n",
       "      <td>04:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.198196</td>\n",
       "      <td>0.195068</td>\n",
       "      <td>0.922920</td>\n",
       "      <td>04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.146078</td>\n",
       "      <td>0.191531</td>\n",
       "      <td>0.928360</td>\n",
       "      <td>04:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.text.all import *\n",
    "\n",
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "learn.fine_tune(4, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e4ac7",
   "metadata": {
    "papermill": {
     "duration": 0.037131,
     "end_time": "2021-08-09T12:00:57.884886",
     "exception": false,
     "start_time": "2021-08-09T12:00:57.847755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:05:08 - Improving results by creating a domain-specific language model\n",
    "\n",
    "* One trick to use is start with a Wikitext language model, then improve it by creating a domain-specific language model. In this example, an IMDb language model.\n",
    "  * Will learn IMDb specific words.\n",
    "  \n",
    "## 00:05:58 - Building a language model from scratch\n",
    "\n",
    "* Sentences can be different lengths. Documents can be very long.\n",
    "* We already looked at using categorical variables as independant variables:\n",
    "  * Make list of all possible levels of the categorical variable (vocab)\n",
    "  * Replace each level with index in vocab\n",
    "  * Create embedding matrix containing a row for each level\n",
    "  * Use embedding matric as first layer of nn\n",
    "* We can almost do the same thing with text.\n",
    "  * Create a list of all words to generate vocab\n",
    "  * Only question is how to use a sequence?\n",
    "* Independant variable is sequence of words from first to 2nd last.\n",
    "* Dependant variable is 2nd word down to last.\n",
    "\n",
    "* When we create vocab, a lot of words will be already in embedding matrix\n",
    "  * May be new ones: informal slang, words not in Wikipedia etc.\n",
    "* For words in Wikipedia, we will use the pretrained embedding vector.\n",
    "* For new words, we will create a new random row.\n",
    "\n",
    "* List of steps:\n",
    "  * **Tokenisation** - convert into a list of words (characters or substrings)\n",
    "  * **Numericalisation** - make a list of unique words in the vocab. Convert each word into a number by looking up the index in vocab\n",
    "  * **Language model data loader** - fastai has `LMDataLoader` which handles creating dependent varible offset from independent by one token.\n",
    "  * **Language model** - need a special model that can handle sequences of arbitrary length.\n",
    "\n",
    "## 00:10:27 - Tokenisation\n",
    "\n",
    "* Converting a text into a list of words.\n",
    "* Questions to ask: What to do with punctuation? How to deal with words like \"don't\"? Long medical or chemical words? etc\n",
    "* 3 common approaches:\n",
    "  * Word-based approached: used by default in English. Split on spaces and applies some language specific rules to separate parts of meaning. Like turning \"don't\" into \"do n't\".  Punctuation marks also split into separate tokens.\n",
    "  * Subword based: split words into smaller parts, based on common occurring substrings. \"occasion\" might be tokenised as \"o c ca sion\"\n",
    "  * Character-based: split sentence into individual characters.\n",
    "  \n",
    "## 00:12:19 - Word tokenisation\n",
    "\n",
    "* fastai doesn't invent its own tokenisers, but provide consistent interface to a range of tokenisers.\n",
    "* Start by getting all text files from IMDB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0583c8f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:00:57.969370Z",
     "iopub.status.busy": "2021-08-09T12:00:57.968742Z",
     "iopub.status.idle": "2021-08-09T12:00:57.971568Z",
     "shell.execute_reply": "2021-08-09T12:00:57.971948Z",
     "shell.execute_reply.started": "2021-08-09T11:20:51.759276Z"
    },
    "papermill": {
     "duration": 0.04633,
     "end_time": "2021-08-09T12:00:57.972082",
     "exception": false,
     "start_time": "2021-08-09T12:00:57.925752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "705227c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:00:58.056518Z",
     "iopub.status.busy": "2021-08-09T12:00:58.055751Z",
     "iopub.status.idle": "2021-08-09T12:00:59.045716Z",
     "shell.execute_reply": "2021-08-09T12:00:59.045209Z",
     "shell.execute_reply.started": "2021-08-09T11:21:25.925381Z"
    },
    "papermill": {
     "duration": 1.032702,
     "end_time": "2021-08-09T12:00:59.045839",
     "exception": false,
     "start_time": "2021-08-09T12:00:58.013137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = get_text_files(path, folders=['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2cb98e",
   "metadata": {
    "papermill": {
     "duration": 0.037756,
     "end_time": "2021-08-09T12:00:59.124989",
     "exception": false,
     "start_time": "2021-08-09T12:00:59.087233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Can get and read first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd7f054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:00:59.210879Z",
     "iopub.status.busy": "2021-08-09T12:00:59.210184Z",
     "iopub.status.idle": "2021-08-09T12:00:59.215728Z",
     "shell.execute_reply": "2021-08-09T12:00:59.216128Z",
     "shell.execute_reply.started": "2021-08-09T11:21:26.908652Z"
    },
    "papermill": {
     "duration": 0.053543,
     "end_time": "2021-08-09T12:00:59.216259",
     "exception": false,
     "start_time": "2021-08-09T12:00:59.162716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jiang Xian uses the complex backstory of Ling Ling and Mao Daobing to study'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = files[0].open().read(); txt[:75]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096fd7ff",
   "metadata": {
    "papermill": {
     "duration": 0.038808,
     "end_time": "2021-08-09T12:00:59.292485",
     "exception": false,
     "start_time": "2021-08-09T12:00:59.253677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Default English word tokeniser called spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c372e277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:00:59.409060Z",
     "iopub.status.busy": "2021-08-09T12:00:59.393520Z",
     "iopub.status.idle": "2021-08-09T12:00:59.747271Z",
     "shell.execute_reply": "2021-08-09T12:00:59.746669Z",
     "shell.execute_reply.started": "2021-08-09T11:21:26.919320Z"
    },
    "papermill": {
     "duration": 0.414653,
     "end_time": "2021-08-09T12:00:59.747450",
     "exception": false,
     "start_time": "2021-08-09T12:00:59.332797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#143) ['Jiang','Xian','uses','the','complex','backstory','of','Ling','Ling','and','Mao','Daobing','to','study','Mao',\"'s\",'\"','cultural','revolution','\"','(','1966','-','1976',')','at','the','village','level','.'...]\n"
     ]
    }
   ],
   "source": [
    "spacy = WordTokenizer()\n",
    "toks = first(spacy([txt]))\n",
    "print(coll_repr(toks, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ff8ad3",
   "metadata": {
    "papermill": {
     "duration": 0.040922,
     "end_time": "2021-08-09T12:00:59.826753",
     "exception": false,
     "start_time": "2021-08-09T12:00:59.785831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a873491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:00:59.909997Z",
     "iopub.status.busy": "2021-08-09T12:00:59.909120Z",
     "iopub.status.idle": "2021-08-09T12:00:59.913171Z",
     "shell.execute_reply": "2021-08-09T12:00:59.912678Z",
     "shell.execute_reply.started": "2021-08-09T11:21:27.370706Z"
    },
    "papermill": {
     "duration": 0.047707,
     "end_time": "2021-08-09T12:00:59.913311",
     "exception": false,
     "start_time": "2021-08-09T12:00:59.865604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#8) ['The','U.S.','dollar','$','1','is','$','1.00']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(spacy(['The U.S. dollar $1 is $1.00']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be51c4",
   "metadata": {
    "papermill": {
     "duration": 0.038042,
     "end_time": "2021-08-09T12:00:59.992883",
     "exception": false,
     "start_time": "2021-08-09T12:00:59.954841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Fastai adds some additional functionality. It adds some \"special tokens\" that start with character `xx`\n",
    "  * `xxbos` indicates start of new text or \"beginning of stream\".\n",
    "  * `xxmaj` - next word beings with capital.\n",
    "  * `xxunk` indicates next word is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da48afc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:00.078778Z",
     "iopub.status.busy": "2021-08-09T12:01:00.078199Z",
     "iopub.status.idle": "2021-08-09T12:01:00.082674Z",
     "shell.execute_reply": "2021-08-09T12:01:00.082235Z",
     "shell.execute_reply.started": "2021-08-09T11:21:27.378689Z"
    },
    "papermill": {
     "duration": 0.047291,
     "end_time": "2021-08-09T12:01:00.082786",
     "exception": false,
     "start_time": "2021-08-09T12:01:00.035495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tkn = Tokenizer(spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43711b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:00.170861Z",
     "iopub.status.busy": "2021-08-09T12:01:00.170207Z",
     "iopub.status.idle": "2021-08-09T12:01:00.172958Z",
     "shell.execute_reply": "2021-08-09T12:01:00.173468Z",
     "shell.execute_reply.started": "2021-08-09T11:21:27.387062Z"
    },
    "papermill": {
     "duration": 0.051335,
     "end_time": "2021-08-09T12:01:00.173621",
     "exception": false,
     "start_time": "2021-08-09T12:01:00.122286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#11) ['xxbos','©','xxmaj','fast.ai','xxrep','3','w','.fast.ai','/','xxup','index']\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_repr(tkn('&copy;    Fast.ai www.fast.ai/INDEX'), 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e4733",
   "metadata": {
    "papermill": {
     "duration": 0.042582,
     "end_time": "2021-08-09T12:01:00.255130",
     "exception": false,
     "start_time": "2021-08-09T12:01:00.212548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:17:38 - Subword tokeniser\n",
    "\n",
    "* In Chinese, they don't use spaces. Instead, they use subword tokenisation.\n",
    "  * Look at corpus of documents and find most commonly occurring groups of letters: they become vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dfe9cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:00.339612Z",
     "iopub.status.busy": "2021-08-09T12:01:00.338641Z",
     "iopub.status.idle": "2021-08-09T12:01:00.432358Z",
     "shell.execute_reply": "2021-08-09T12:01:00.431684Z",
     "shell.execute_reply.started": "2021-08-09T11:21:27.398774Z"
    },
    "papermill": {
     "duration": 0.138928,
     "end_time": "2021-08-09T12:01:00.432545",
     "exception": false,
     "start_time": "2021-08-09T12:01:00.293617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "txts = L(o.open().read() for o in files[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705373f0",
   "metadata": {
    "papermill": {
     "duration": 0.037805,
     "end_time": "2021-08-09T12:01:00.513717",
     "exception": false,
     "start_time": "2021-08-09T12:01:00.475912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* This function `setup` is used to prepare or train some transformations. In this example, it trains on a subset of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6712f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:00.642544Z",
     "iopub.status.busy": "2021-08-09T12:01:00.641581Z",
     "iopub.status.idle": "2021-08-09T12:01:00.644066Z",
     "shell.execute_reply": "2021-08-09T12:01:00.644556Z",
     "shell.execute_reply.started": "2021-08-09T11:21:27.517501Z"
    },
    "papermill": {
     "duration": 0.089671,
     "end_time": "2021-08-09T12:01:00.644700",
     "exception": false,
     "start_time": "2021-08-09T12:01:00.555029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subword(sz):\n",
    "    sp = SubwordTokenizer(vocab_sz=sz)\n",
    "    sp.setup(txts)\n",
    "    return ' '.join(first(sp([txt]))[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69cf53cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:00.729210Z",
     "iopub.status.busy": "2021-08-09T12:01:00.728678Z",
     "iopub.status.idle": "2021-08-09T12:01:11.197080Z",
     "shell.execute_reply": "2021-08-09T12:01:11.197759Z",
     "shell.execute_reply.started": "2021-08-09T11:21:27.545455Z"
    },
    "papermill": {
     "duration": 10.511354,
     "end_time": "2021-08-09T12:01:11.197916",
     "exception": false,
     "start_time": "2021-08-09T12:01:00.686562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'▁J i ang ▁ X ian ▁us es ▁the ▁comp le x ▁back st or y ▁of ▁L ing ▁L ing ▁and ▁Ma o ▁Da o b ing ▁to ▁st u d y ▁Ma o \\' s ▁\" c ul'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6766ce8b",
   "metadata": {
    "papermill": {
     "duration": 0.037609,
     "end_time": "2021-08-09T12:01:11.275019",
     "exception": false,
     "start_time": "2021-08-09T12:01:11.237410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* With a larger vocab, most common English words end up in vocab itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f633a52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:11.355675Z",
     "iopub.status.busy": "2021-08-09T12:01:11.354183Z",
     "iopub.status.idle": "2021-08-09T12:01:16.518449Z",
     "shell.execute_reply": "2021-08-09T12:01:16.519636Z",
     "shell.execute_reply.started": "2021-08-09T11:21:40.459022Z"
    },
    "papermill": {
     "duration": 5.207201,
     "end_time": "2021-08-09T12:01:16.519890",
     "exception": false,
     "start_time": "2021-08-09T12:01:11.312689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'▁J ian g ▁X ian ▁uses ▁the ▁complex ▁back story ▁of ▁L ing ▁L ing ▁and ▁Ma o ▁Da ob ing ▁to ▁study ▁Ma o \\' s ▁\" cul t ural ▁revolution \" ▁( 1966 - 1 9 7 6'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdaaca",
   "metadata": {
    "papermill": {
     "duration": 0.065329,
     "end_time": "2021-08-09T12:01:16.651708",
     "exception": false,
     "start_time": "2021-08-09T12:01:16.586379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Jeremy predicts that subword will be the most popular form of tokenisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf9b14",
   "metadata": {
    "papermill": {
     "duration": 0.065608,
     "end_time": "2021-08-09T12:01:16.782959",
     "exception": false,
     "start_time": "2021-08-09T12:01:16.717351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:21:21 - Question: how can we determine if pretrained model is suitable for downstream task? If there's limited vocab overlap, should we create a language model from scratch\n",
    "\n",
    "* In same language, Wikitext usually works well.\n",
    "* If you were using Genomic sequences, or Greek then you would likely need a domain-specific language model.\n",
    "\n",
    "## 00:23:25 - Numericalization\n",
    "\n",
    "* After splitting into tokens, the next step is numericalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b0fc5cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:16.925373Z",
     "iopub.status.busy": "2021-08-09T12:01:16.924611Z",
     "iopub.status.idle": "2021-08-09T12:01:17.877852Z",
     "shell.execute_reply": "2021-08-09T12:01:17.877061Z",
     "shell.execute_reply.started": "2021-08-09T11:21:45.906972Z"
    },
    "papermill": {
     "duration": 1.028813,
     "end_time": "2021-08-09T12:01:17.877996",
     "exception": false,
     "start_time": "2021-08-09T12:01:16.849183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#158) ['xxbos','xxmaj','jiang','xxmaj','xian','uses','the','complex','backstory','of'...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks200 = txts[:200].map(tkn)\n",
    "toks200[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e73174",
   "metadata": {
    "papermill": {
     "duration": 0.039728,
     "end_time": "2021-08-09T12:01:17.958053",
     "exception": false,
     "start_time": "2021-08-09T12:01:17.918325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Can then pass into `setup` to create `vocab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb79f3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:18.058625Z",
     "iopub.status.busy": "2021-08-09T12:01:18.057350Z",
     "iopub.status.idle": "2021-08-09T12:01:18.060715Z",
     "shell.execute_reply": "2021-08-09T12:01:18.061119Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.757140Z"
    },
    "papermill": {
     "duration": 0.063349,
     "end_time": "2021-08-09T12:01:18.061253",
     "exception": false,
     "start_time": "2021-08-09T12:01:17.997904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#2152) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the',',','.','and','a','of','to','is','in','it','i'...]\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = Numericalize()\n",
    "num.setup(toks200)\n",
    "coll_repr(num.vocab, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a5c5b",
   "metadata": {
    "papermill": {
     "duration": 0.040268,
     "end_time": "2021-08-09T12:01:18.142988",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.102720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* The tokens are in order of frequency.\n",
    "  * Defaults:\n",
    "    * `min_freq=3` - minimum frequency required.\n",
    "    * `max_vocab=60000` - limit the size of the embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288fe6f",
   "metadata": {
    "papermill": {
     "duration": 0.040502,
     "end_time": "2021-08-09T12:01:18.225099",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.184597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Can now call `num` as if it was a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fab9a1c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:18.310418Z",
     "iopub.status.busy": "2021-08-09T12:01:18.309759Z",
     "iopub.status.idle": "2021-08-09T12:01:18.315850Z",
     "shell.execute_reply": "2021-08-09T12:01:18.315413Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.780068Z"
    },
    "papermill": {
     "duration": 0.05039,
     "end_time": "2021-08-09T12:01:18.315956",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.265566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([   0,    0, 1268,    9, 1269,    0,   14,    0,    0,   12,    0,    0,\n",
       "          15, 1270,    0,   22,   24,    0,  795,   24])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = num(toks)[:20]; nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ecbd0",
   "metadata": {
    "papermill": {
     "duration": 0.040253,
     "end_time": "2021-08-09T12:01:18.397144",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.356891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Can convert back by indexing into vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d0f08b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:18.485145Z",
     "iopub.status.busy": "2021-08-09T12:01:18.484499Z",
     "iopub.status.idle": "2021-08-09T12:01:18.487616Z",
     "shell.execute_reply": "2021-08-09T12:01:18.488005Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.812411Z"
    },
    "papermill": {
     "duration": 0.050284,
     "end_time": "2021-08-09T12:01:18.488226",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.437942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk xxunk uses the complex xxunk of xxunk xxunk and xxunk xxunk to study xxunk \\'s \" xxunk revolution \"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(num.vocab[o] for o in nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8bb638",
   "metadata": {
    "papermill": {
     "duration": 0.040421,
     "end_time": "2021-08-09T12:01:18.569245",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.528824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:25:43 - Putting texts into batches for language model\n",
    "\n",
    "* Items in a mini-batch need to be the same size to be stacked in Tensor.\n",
    "    * With images, we resize them all to a consistent size.\n",
    "* How do we do it with text?\n",
    "* We could break into contiguous blocks that match our batch size. Here's an example of a batch size of 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f4886c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:18.661793Z",
     "iopub.status.busy": "2021-08-09T12:01:18.661006Z",
     "iopub.status.idle": "2021-08-09T12:01:18.686443Z",
     "shell.execute_reply": "2021-08-09T12:01:18.685891Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.821275Z"
    },
    "papermill": {
     "duration": 0.076802,
     "end_time": "2021-08-09T12:01:18.686570",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.609768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>chapter</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "      <td>back</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>classifying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "      <td>in</td>\n",
       "      <td>chapter</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "      <td>deeper</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "      <td>block</td>\n",
       "      <td>xxup</td>\n",
       "      <td>api</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "      <td>it</td>\n",
       "      <td>for</td>\n",
       "      <td>a</td>\n",
       "      <td>while</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1             2        3        4        5           6      7   \\\n",
       "0  xxbos    xxmaj            in     this  chapter        ,          we   will   \n",
       "1  movie  reviews            we  studied       in  chapter           1    and   \n",
       "2  first       we          will     look       at      the  processing  steps   \n",
       "3    how       to     customize       it        .    xxmaj          by  doing   \n",
       "4     of      the  preprocessor     used       in      the        data  block   \n",
       "5   will    study           how       we    build        a    language  model   \n",
       "\n",
       "          8       9        10    11       12       13           14  \n",
       "0         go    back     over   the  example       of  classifying  \n",
       "1        dig  deeper    under   the  surface        .        xxmaj  \n",
       "2  necessary      to  convert  text     into  numbers          and  \n",
       "3       this       ,       we   'll     have  another      example  \n",
       "4       xxup     api        .    \\n    xxmaj     then           we  \n",
       "5        and   train       it   for        a    while            .  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = \"In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while.\"\n",
    "tokens = tkn(stream)\n",
    "bs,seq_len = 6,15\n",
    "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb9447",
   "metadata": {
    "papermill": {
     "duration": 0.040697,
     "end_time": "2021-08-09T12:01:18.768920",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.728223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* That won't scale to a giant corpus, so we have to divide into subarrays with a fixed sequence length.\n",
    "* Let's try a sequence length of 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1ed25e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:18.864919Z",
     "iopub.status.busy": "2021-08-09T12:01:18.864227Z",
     "iopub.status.idle": "2021-08-09T12:01:18.867522Z",
     "shell.execute_reply": "2021-08-09T12:01:18.867915Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.852412Z"
    },
    "papermill": {
     "duration": 0.057777,
     "end_time": "2021-08-09T12:01:18.868056",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.810279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>chapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>preprocessor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1             2        3        4\n",
       "0  xxbos    xxmaj            in     this  chapter\n",
       "1  movie  reviews            we  studied       in\n",
       "2  first       we          will     look       at\n",
       "3    how       to     customize       it        .\n",
       "4     of      the  preprocessor     used       in\n",
       "5   will    study           how       we    build"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,seq_len = 6,5\n",
    "d_tokens = np.array([tokens[i*15:i*15+seq_len] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958c69d",
   "metadata": {
    "papermill": {
     "duration": 0.041252,
     "end_time": "2021-08-09T12:01:18.951120",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.909868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Then the next batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7dfab7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:19.047625Z",
     "iopub.status.busy": "2021-08-09T12:01:19.046593Z",
     "iopub.status.idle": "2021-08-09T12:01:19.050996Z",
     "shell.execute_reply": "2021-08-09T12:01:19.050564Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.866580Z"
    },
    "papermill": {
     "duration": 0.058382,
     "end_time": "2021-08-09T12:01:19.051115",
     "exception": false,
     "start_time": "2021-08-09T12:01:18.992733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chapter</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "      <td>deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "      <td>block</td>\n",
       "      <td>xxup</td>\n",
       "      <td>api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0           1      2          3       4\n",
       "0        ,          we   will         go    back\n",
       "1  chapter           1    and        dig  deeper\n",
       "2      the  processing  steps  necessary      to\n",
       "3    xxmaj          by  doing       this       ,\n",
       "4      the        data  block       xxup     api\n",
       "5        a    language  model        and   train"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "bs,seq_len = 6,5\n",
    "d_tokens = np.array([tokens[i*15+seq_len:i*15+2*seq_len] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ccbdf",
   "metadata": {
    "papermill": {
     "duration": 0.042437,
     "end_time": "2021-08-09T12:01:19.136190",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.093753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* And so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c9201",
   "metadata": {
    "papermill": {
     "duration": 0.041287,
     "end_time": "2021-08-09T12:01:19.220655",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.179368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:29:24 - LMDataLoader\n",
    "\n",
    "* Don't have to do these steps yourself, `LMDataLoader` in fastai handles it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2f1cf87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:19.363577Z",
     "iopub.status.busy": "2021-08-09T12:01:19.362773Z",
     "iopub.status.idle": "2021-08-09T12:01:19.365781Z",
     "shell.execute_reply": "2021-08-09T12:01:19.365370Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.883782Z"
    },
    "papermill": {
     "duration": 0.102997,
     "end_time": "2021-08-09T12:01:19.365897",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.262900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nums200 = toks200.map(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "603b8e3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:19.459198Z",
     "iopub.status.busy": "2021-08-09T12:01:19.458626Z",
     "iopub.status.idle": "2021-08-09T12:01:19.461358Z",
     "shell.execute_reply": "2021-08-09T12:01:19.461735Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.939127Z"
    },
    "papermill": {
     "duration": 0.053411,
     "end_time": "2021-08-09T12:01:19.461872",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.408461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl = LMDataLoader(nums200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7132744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:19.549983Z",
     "iopub.status.busy": "2021-08-09T12:01:19.549464Z",
     "iopub.status.idle": "2021-08-09T12:01:19.568688Z",
     "shell.execute_reply": "2021-08-09T12:01:19.568247Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.951970Z"
    },
    "papermill": {
     "duration": 0.06486,
     "end_time": "2021-08-09T12:01:19.568803",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.503943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 72]), torch.Size([64, 72]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = first(dl)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc61a1",
   "metadata": {
    "papermill": {
     "duration": 0.041755,
     "end_time": "2021-08-09T12:01:19.652827",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.611072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* 64 is batch size and 72 is sequence size.\n",
    "* Can examine the first 20 tokens of independent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d91e1962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:19.744074Z",
     "iopub.status.busy": "2021-08-09T12:01:19.743341Z",
     "iopub.status.idle": "2021-08-09T12:01:19.746282Z",
     "shell.execute_reply": "2021-08-09T12:01:19.746748Z",
     "shell.execute_reply.started": "2021-08-09T11:21:46.989067Z"
    },
    "papermill": {
     "duration": 0.051564,
     "end_time": "2021-08-09T12:01:19.746874",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.695310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj xxunk xxmaj xxunk uses the complex xxunk of xxmaj xxunk xxmaj xxunk and xxmaj xxunk xxmaj xxunk to'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(num.vocab[o] for o in x[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bfc73",
   "metadata": {
    "papermill": {
     "duration": 0.042107,
     "end_time": "2021-08-09T12:01:19.831634",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.789527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* then dependent variable, which is the same thing offset by one token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c8a133e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:19.920049Z",
     "iopub.status.busy": "2021-08-09T12:01:19.919265Z",
     "iopub.status.idle": "2021-08-09T12:01:19.925504Z",
     "shell.execute_reply": "2021-08-09T12:01:19.925945Z",
     "shell.execute_reply.started": "2021-08-09T11:21:47.002306Z"
    },
    "papermill": {
     "duration": 0.052172,
     "end_time": "2021-08-09T12:01:19.926096",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.873924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxmaj xxunk xxmaj xxunk uses the complex xxunk of xxmaj xxunk xxmaj xxunk and xxmaj xxunk xxmaj xxunk to study'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(num.vocab[o] for o in y[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e27c36",
   "metadata": {
    "papermill": {
     "duration": 0.04232,
     "end_time": "2021-08-09T12:01:20.011152",
     "exception": false,
     "start_time": "2021-08-09T12:01:19.968832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:31:07 - Creating language model with DataBlock\n",
    "\n",
    "* In the DataBlock instance, we're using a `TextBlock` from the block argument.\n",
    "  * Passing in a class method, allows the tokenisation to be cached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a171155d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:20.181037Z",
     "iopub.status.busy": "2021-08-09T12:01:20.136390Z",
     "iopub.status.idle": "2021-08-09T12:01:25.620549Z",
     "shell.execute_reply": "2021-08-09T12:01:25.619931Z",
     "shell.execute_reply.started": "2021-08-09T11:21:47.009961Z"
    },
    "papermill": {
     "duration": 5.566157,
     "end_time": "2021-08-09T12:01:25.620690",
     "exception": false,
     "start_time": "2021-08-09T12:01:20.054533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
    "\n",
    "dls_lm = DataBlock(\n",
    "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
    "    get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
    ").dataloaders(path, path=path, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e002ee7",
   "metadata": {
    "papermill": {
     "duration": 0.042008,
     "end_time": "2021-08-09T12:01:25.705678",
     "exception": false,
     "start_time": "2021-08-09T12:01:25.663670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Note the items are text items from folders.\n",
    "* We can then call show_batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d5e6864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:25.824588Z",
     "iopub.status.busy": "2021-08-09T12:01:25.814467Z",
     "iopub.status.idle": "2021-08-09T12:01:26.631405Z",
     "shell.execute_reply": "2021-08-09T12:01:26.631826Z",
     "shell.execute_reply.started": "2021-08-09T11:27:38.671200Z"
    },
    "papermill": {
     "duration": 0.884542,
     "end_time": "2021-08-09T12:01:26.631972",
     "exception": false,
     "start_time": "2021-08-09T12:01:25.747430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj this movie is so xxup stupid ! i mean .. why does xxmaj liam xxmaj neeson take this woman so seriously , having only heard her say 3 xxup words ! xxmaj when they found her in the woods , they should xxunk have committed her to psychiatric hospital to try and make her a real human being . xxmaj just to see xxmaj jodie \" hey - see how stupid i look \" xxmaj foster dance around</td>\n",
       "      <td>xxmaj this movie is so xxup stupid ! i mean .. why does xxmaj liam xxmaj neeson take this woman so seriously , having only heard her say 3 xxup words ! xxmaj when they found her in the woods , they should xxunk have committed her to psychiatric hospital to try and make her a real human being . xxmaj just to see xxmaj jodie \" hey - see how stupid i look \" xxmaj foster dance around chanting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tracking down vehicles that may have entered the crime scene from camera - visible locations adjacent to the crime scene as part of developing clues . \\n\\n * xxmaj in xxmaj england , driving is on the left . xxmaj the director goes out of his way to have the car at the crime scene park on the right , several meters away from the flower kiosk , when it could have easily parked immediately behind , or even on</td>\n",
       "      <td>down vehicles that may have entered the crime scene from camera - visible locations adjacent to the crime scene as part of developing clues . \\n\\n * xxmaj in xxmaj england , driving is on the left . xxmaj the director goes out of his way to have the car at the crime scene park on the right , several meters away from the flower kiosk , when it could have easily parked immediately behind , or even on the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d60ed",
   "metadata": {
    "papermill": {
     "duration": 0.042108,
     "end_time": "2021-08-09T12:01:26.716227",
     "exception": false,
     "start_time": "2021-08-09T12:01:26.674119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:33:23 - Fine tuning a language model\n",
    "\n",
    "* Fine tuning language model creates a learning which learns to predict next word of music review.\n",
    "* `AWD_LSTM` is the architecture.\n",
    "* `drop_mult` is amount of Dropout (covered later in the course)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703096a1",
   "metadata": {
    "papermill": {
     "duration": 0.041713,
     "end_time": "2021-08-09T12:01:26.799839",
     "exception": false,
     "start_time": "2021-08-09T12:01:26.758126",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e0f7f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:26.889088Z",
     "iopub.status.busy": "2021-08-09T12:01:26.888315Z",
     "iopub.status.idle": "2021-08-09T12:01:28.697578Z",
     "shell.execute_reply": "2021-08-09T12:01:28.698002Z",
     "shell.execute_reply.started": "2021-08-09T11:31:46.225079Z"
    },
    "papermill": {
     "duration": 1.856086,
     "end_time": "2021-08-09T12:01:28.698163",
     "exception": false,
     "start_time": "2021-08-09T12:01:26.842077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(\n",
    "    dls_lm, AWD_LSTM, drop_mult=0.3,\n",
    "    metrics=[accuracy, Perplexity()],\n",
    "    path='/kaggle/working'\n",
    ").to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "730e71ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:01:28.785942Z",
     "iopub.status.busy": "2021-08-09T12:01:28.785437Z",
     "iopub.status.idle": "2021-08-09T12:29:14.402157Z",
     "shell.execute_reply": "2021-08-09T12:29:14.402680Z",
     "shell.execute_reply.started": "2021-08-09T11:27:44.734073Z"
    },
    "papermill": {
     "duration": 1665.662494,
     "end_time": "2021-08-09T12:29:14.402853",
     "exception": false,
     "start_time": "2021-08-09T12:01:28.740359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.006212</td>\n",
       "      <td>3.899826</td>\n",
       "      <td>0.300805</td>\n",
       "      <td>49.393833</td>\n",
       "      <td>27:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f718a86",
   "metadata": {
    "papermill": {
     "duration": 0.042222,
     "end_time": "2021-08-09T12:29:14.489056",
     "exception": false,
     "start_time": "2021-08-09T12:29:14.446834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:35:07 - Saving and loading models\n",
    "\n",
    "* Can use `learn.save` to save intermediary results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f94d7441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:29:14.591947Z",
     "iopub.status.busy": "2021-08-09T12:29:14.591188Z",
     "iopub.status.idle": "2021-08-09T12:29:15.432419Z",
     "shell.execute_reply": "2021-08-09T12:29:15.432809Z",
     "shell.execute_reply.started": "2021-08-09T11:31:52.648854Z"
    },
    "papermill": {
     "duration": 0.90174,
     "end_time": "2021-08-09T12:29:15.432961",
     "exception": false,
     "start_time": "2021-08-09T12:29:14.531221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/kaggle/working/models/1epoch.pth')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save('1epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abfa2b",
   "metadata": {
    "papermill": {
     "duration": 0.042661,
     "end_time": "2021-08-09T12:29:15.518778",
     "exception": false,
     "start_time": "2021-08-09T12:29:15.476117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And load with `learn.load`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84cf30ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:29:15.610852Z",
     "iopub.status.busy": "2021-08-09T12:29:15.610000Z",
     "iopub.status.idle": "2021-08-09T12:29:15.866801Z",
     "shell.execute_reply": "2021-08-09T12:29:15.867212Z",
     "shell.execute_reply.started": "2021-08-09T11:32:00.544417Z"
    },
    "papermill": {
     "duration": 0.306328,
     "end_time": "2021-08-09T12:29:15.867374",
     "exception": false,
     "start_time": "2021-08-09T12:29:15.561046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.text.learner.LMLearner at 0x7fa49e0a2e10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('1epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe865f",
   "metadata": {
    "papermill": {
     "duration": 0.042998,
     "end_time": "2021-08-09T12:29:15.953439",
     "exception": false,
     "start_time": "2021-08-09T12:29:15.910441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Can then finetune after unfreezing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfb1ca59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T12:29:16.042436Z",
     "iopub.status.busy": "2021-08-09T12:29:16.041904Z",
     "iopub.status.idle": "2021-08-09T17:32:11.554626Z",
     "shell.execute_reply": "2021-08-09T17:32:11.554187Z"
    },
    "papermill": {
     "duration": 18175.558848,
     "end_time": "2021-08-09T17:32:11.554757",
     "exception": false,
     "start_time": "2021-08-09T12:29:15.995909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.763982</td>\n",
       "      <td>3.759459</td>\n",
       "      <td>0.316605</td>\n",
       "      <td>42.925179</td>\n",
       "      <td>30:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.684646</td>\n",
       "      <td>3.699707</td>\n",
       "      <td>0.323066</td>\n",
       "      <td>40.435436</td>\n",
       "      <td>30:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.623890</td>\n",
       "      <td>3.654301</td>\n",
       "      <td>0.328286</td>\n",
       "      <td>38.640499</td>\n",
       "      <td>30:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.564344</td>\n",
       "      <td>3.620885</td>\n",
       "      <td>0.332433</td>\n",
       "      <td>37.370613</td>\n",
       "      <td>30:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.501577</td>\n",
       "      <td>3.598828</td>\n",
       "      <td>0.335188</td>\n",
       "      <td>36.555359</td>\n",
       "      <td>30:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.427867</td>\n",
       "      <td>3.579867</td>\n",
       "      <td>0.337651</td>\n",
       "      <td>35.868767</td>\n",
       "      <td>30:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.362838</td>\n",
       "      <td>3.575086</td>\n",
       "      <td>0.339170</td>\n",
       "      <td>35.697678</td>\n",
       "      <td>30:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.302284</td>\n",
       "      <td>3.569533</td>\n",
       "      <td>0.340268</td>\n",
       "      <td>35.499996</td>\n",
       "      <td>30:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.239792</td>\n",
       "      <td>3.574208</td>\n",
       "      <td>0.340490</td>\n",
       "      <td>35.666363</td>\n",
       "      <td>30:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.215606</td>\n",
       "      <td>3.578157</td>\n",
       "      <td>0.340285</td>\n",
       "      <td>35.807476</td>\n",
       "      <td>30:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69448e",
   "metadata": {
    "papermill": {
     "duration": 0.050424,
     "end_time": "2021-08-09T17:32:11.653132",
     "exception": false,
     "start_time": "2021-08-09T17:32:11.602708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* We can then save just the encoder.\n",
    "* Encoder is all of the model that isn't the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "010239dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T17:32:11.755409Z",
     "iopub.status.busy": "2021-08-09T17:32:11.754609Z",
     "iopub.status.idle": "2021-08-09T17:32:12.150939Z",
     "shell.execute_reply": "2021-08-09T17:32:12.150387Z"
    },
    "papermill": {
     "duration": 0.450609,
     "end_time": "2021-08-09T17:32:12.151098",
     "exception": false,
     "start_time": "2021-08-09T17:32:11.700489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.save_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3912d329",
   "metadata": {
    "papermill": {
     "duration": 0.045049,
     "end_time": "2021-08-09T17:32:12.245183",
     "exception": false,
     "start_time": "2021-08-09T17:32:12.200134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:36:44 - Question: Do language models attempt to provide meaning?\n",
    "\n",
    "* Language model do tend to get good at understanding nuances of languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf5022",
   "metadata": {
    "papermill": {
     "duration": 0.049313,
     "end_time": "2021-08-09T17:32:12.344988",
     "exception": false,
     "start_time": "2021-08-09T17:32:12.295675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 00:37:56 - Text generation (next notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21598.455181,
   "end_time": "2021-08-09T17:32:15.412282",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-09T11:32:16.957101",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
