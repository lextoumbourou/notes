---
title: "Machine learning and information theory concepts towards an AI Mathematician"
date: 2024-10-13 00:00
modified: 2024-10-13 00:00
status: draft
---

These are my notes from paper [Machine learning and information theory concepts towards an AI Mathematician](https://arxiv.org/abs/2403.04571) by Yoshua Bengio, Nikolay Malkin.

---

The essay builds on the idea that current deep learning behaviour is mostly akin to [System 1 Thinking](../permanent/system-1-thinking.md), corresponding to our intuition and behaviour of habits. But they still lack [System 2 Thinking](../permanent/system-2-thinking.md) abilities, including reasoning and robust uncertainty estimation.

Drawing on information theory, the authors suggest a new training objective: creating a compressed library of mathematical statements that can efficiently generate many provable statements. In the Compression as a General Learning Theory Principle, "compression" is argued to be key to discovering new and interesting conjectures, which could then be proven using a goal-conditioned machine learning approach

The paper explores how these ideas can be applied to the development of an "AI mathematician" capable of generating and proving theorems, drawing parallels between this process and active learning, curriculum learning, and reinforcement learning techniques in AI.

Ultimately, the authors present a framework for creating an AI system that can learn from existing mathematical knowledge and independently explore and discover new mathematical truths.
