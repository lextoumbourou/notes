---
title: "OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training"
date: 2024-10-15 00:00
modified: 2024-10-15 00:00
status: draft
---

OpenDiLoCo is an open-source framework for training large language models efficiently across geographically distributed devices. The framework is built on top of the Hivemind library, and it implements the Distributed Low-Communication (DiLoCo) method, which dramatically reduces the need for frequent communication between devices. OpenDiLoCo achieves high compute utilisation by training models across multiple continents and countries, even with limited bandwidth. The paper describes the framework's implementation, including a reference implementation using PyTorch and a Hivemind-based implementation. It also presents experimental results showing OpenDiLoCo's effectiveness and scalability for training models with billions of parameters.

![](../../../../_media/opendiloco-an-open-source-framework-for-globally-distributed-low-communication-trainin-title.png)
![](../../../../_media/opendiloco-an-open-source-framework-for-globally-distributed-low-communication-trainin-abstract.png)
